---
title: 理解分布式系统的设计
tags:
---

分布式存储系统是非常复杂的，因为网络、节点都是不可靠的，而我们要在不可靠的基础上构建可靠的系统。一些论文描述了一些解决方案，但是单独的去看这些论文是比较晦涩的。我们需要按照历史的发展来理解这些问题。**只有了解了前因后果，我们才有可能在前人的基础上提出我们自己的解决方案。**同时我们也需要知道这些方案提出者，**灵感的来源是什么？**当他将他的思想成果写成论文的时候，他们会将自己的论文包装的天衣无缝，好像他们一开始就知道了答案一样。让我们从头开始思考分布式存储的问题。

## 本地存储的问题

写入性能问题：磁盘IO是比较慢的，如何提高写入的性能。

本地数据一致问题问题： 系统可能在任何时间崩溃，多条指令可能只有部分成功。我们对内存、日志、磁盘数据结构的写入可能只有部分成功，**如何保证本地数据是一致的?**

写入内存的速度是最快的。但内存是不可靠的，因此必须以写入磁盘作为写入成功的保证。但写入最终数据比较慢，有时还需要考虑数据压缩等必须延后操作的任务，我们必须要以最小的成本写入磁盘，先保证数据写入是可靠的。之后再用异步的方式优化存储的结构，这是很容易想到的某种磁盘上的空间换时间。

我们先写入日志，再写入内存，最后批量写入磁盘数据结构，任何一步失败则停止后续动作。在查询的时候，先查询内存，再查询磁盘。如果在写入日志时失败，则直接失败，服务恢复后数据一致。写入内存失败，相当于崩溃，服务恢复后从日志恢复数据。如果在写入内存成功、写入磁盘数据结构时失败。内存数据依然能够提供查询的需要，同时由同步线程定时重试，写入磁盘数据。这样我们就保证了本地数据的一致性。这里引申出一个问题：**如何有效的从日志恢复数据？**

如果日志量过大，重放需要很长的时间，因此我们可以使用检查点技术。在每一个检查点，我们都保证了数据的一致性，并保存了当时的一些元信息状态。当我们在数据恢复时，只需要从检查点开始进行日志重放即可。

我们在本地存储中也需要加入checksum的机制，用于防止磁盘的机械物理错误。为了防止一个小的物理错误致使整个节点的数据失效，我们也需要将本地的存储划分为不同的部分，某一部分的损坏不影响其他部分的数据。这里引申出一个问题：如何设计本地存储的分块。

我们还忽略了一个重要的问题，查询性能与写入性能，这都是直接与数据库本身的设计特点直接相关的内容，还需要考虑如何减少磁盘访问次数，如B+树，元数据表等，这里不展开。另一个复杂的本地存储的问题是，含有多个操作的事务如何保证原子性。

## 分布式存储的问题

数据完整性问题：节点、存储都是不可靠的，他们都有一定的概率崩溃、损坏。 只有冗余能够保证数据的完整性。我们需要至少2个副本才能基本保证可靠，一般而言，我们要有至少3个副本，以免两个副本同时损坏。分布式系统带来了很多问题：

1. 不同节点只保存了部分数据，如何确定某个key存在哪个节点上？
2. 不同节点的数据分布可能是不均匀的，如何平衡各个节点的存储？
3. 写入成功问题。如果只是简单的向不同节点广播写入key的操作请求，那么可能是部分成功，部分失败，如何保证不同节点同一个Key的值最终是一致的。也就是说每个分布式写操作，要么成功要么失败。
4. 同一个key不同副本的数据可能暂时是不一致的，读取应该采取什么策略返回数据。
5. 操作的顺序问题。Key foo的值为A，对于Key foo有两个并发的操作，一个将之改为B，一个将之改为C。这两个指令到达不同节点的先后顺序可能是不同的，那么Key foo在两个节点上的值如何保持一致？

以上问题又可以引申出以下问题：

1. leader选举问题
2. 分布式升序时间问题
3. 分布式ID唯一性
4. 共识问题

如何使系统容量能线性的扩展？我们不能让两个节点的数据块分布一模一样，我们要使他们尽量的保持『正交』。假设我们有ABC三个节点，我们有1234几个数据块。我们可以 A(1,2,3),B(2,3,4),C(4,1) 类似的方式，来分布数据，这样我们在恢复数据时的性能也能得到提升。

如何保证一个强一致事务至少2个副本写入成功？

分区数据一致性问题：对于多个节点的操作可能也只有部分成功。我们如何判定某个操作是成功的。如：本地写入成功即认为成功，至少两个节点写入成功才算成功。这里引申出一个问题：网络操作有 成功、失败、超时三种状态，超时状态不能简单认为失败，要如何处理？

**三态问题的关键是消除不确定的超时状态，使之能够确定成功/失败两种状态。**或者说，我们要找到成功与失败的临界点。对于这个问题的解决思路来源于人类的活动。人类每个个体都可以视为一个分布式节点，当我们的通信不可靠时，人类是如何完成最终的决定的呢？这类算法被称为**共识算法**

2PC, 3PC 依靠一个协调者来做最终的决策，成功和失败的临界点就在协调者做出决策并成功将协调者状态写入磁盘的时刻。但如果协调者出了问题怎么办？只能等待协调者恢复。



Paxos 的灵感来源于民主制度。

Raft 是对 Paxos 的改进

Ark

[一致性算法资料](http://neurocline.github.io/dev/2015/08/09/consensus-algorithms.html)

